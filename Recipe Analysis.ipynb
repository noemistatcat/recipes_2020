{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Set options\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_seq_items = 2000\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20047</th>\n",
       "      <td>Parmesan Puffs</td>\n",
       "      <td>3.125</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20048</th>\n",
       "      <td>Artichoke and Parmesan Risotto</td>\n",
       "      <td>4.375</td>\n",
       "      <td>671.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20049</th>\n",
       "      <td>Turkey Cream Puff Pie</td>\n",
       "      <td>4.375</td>\n",
       "      <td>563.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20050</th>\n",
       "      <td>Snapper on Angel Hair with Citrus Cream</td>\n",
       "      <td>4.375</td>\n",
       "      <td>631.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20051</th>\n",
       "      <td>Baked Ham with Marmalade-Horseradish Glaze</td>\n",
       "      <td>4.375</td>\n",
       "      <td>560.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  rating  calories  protein  \\\n",
       "20047                              Parmesan Puffs    3.125      28.0      2.0   \n",
       "20048              Artichoke and Parmesan Risotto    4.375     671.0     22.0   \n",
       "20049                       Turkey Cream Puff Pie    4.375     563.0     31.0   \n",
       "20050     Snapper on Angel Hair with Citrus Cream    4.375     631.0     45.0   \n",
       "20051  Baked Ham with Marmalade-Horseradish Glaze    4.375     560.0     73.0   \n",
       "\n",
       "        fat  sodium  #cakeweek  #wasteless  22-minute meals  \\\n",
       "20047   2.0    64.0          0           0                0   \n",
       "20048  28.0   583.0          0           0                0   \n",
       "20049  38.0   652.0          0           0                0   \n",
       "20050  24.0   517.0          0           0                0   \n",
       "20051  10.0  3698.0          0           0                0   \n",
       "\n",
       "       3-ingredient recipes  ...  yellow squash  yogurt  yonkers  yuca  \\\n",
       "20047                     0  ...              0       0        0     0   \n",
       "20048                     0  ...              0       0        0     0   \n",
       "20049                     0  ...              0       0        0     0   \n",
       "20050                     0  ...              0       0        0     0   \n",
       "20051                     0  ...              0       0        0     0   \n",
       "\n",
       "       zucchini  cookbooks  leftovers  snack  snack week  turkey  \n",
       "20047         0          0          0      0           0       0  \n",
       "20048         0          0          0      0           0       0  \n",
       "20049         0          0          0      0           0       1  \n",
       "20050         0          0          0      0           0       0  \n",
       "20051         0          0          0      0           0       0  \n",
       "\n",
       "[5 rows x 680 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv(\"recipes.csv\", encoding='utf_8')\n",
    "df = df.drop_duplicates()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'rating', 'calories', 'protein', 'fat', 'sodium', '#cakeweek',\n",
      "       '#wasteless', '22-minute meals', '3-ingredient recipes',\n",
      "       '30 days of groceries', 'advance prep required', 'alabama', 'alaska',\n",
      "       'alcoholic', 'almond', 'amaretto', 'anchovy', 'anise', 'anniversary',\n",
      "       'anthony bourdain', 'aperitif', 'appetizer', 'apple', 'apple juice',\n",
      "       'apricot', 'arizona', 'artichoke', 'arugula', 'asian pear', 'asparagus',\n",
      "       'aspen', 'atlanta', 'australia', 'avocado', 'back to school',\n",
      "       'backyard bbq', 'bacon', 'bake', 'banana', 'barley', 'basil', 'bass',\n",
      "       'bastille day', 'bean', 'beef', 'beef rib', 'beef shank',\n",
      "       'beef tenderloin', 'beer', 'beet', 'bell pepper', 'berry',\n",
      "       'beverly hills', 'birthday', 'biscuit', 'bitters', 'blackberry',\n",
      "       'blender', 'blue cheese', 'blueberry', 'boil', 'bok choy',\n",
      "       'bon appétit', 'bon app��tit', 'boston', 'bourbon', 'braise', 'bran',\n",
      "       'brandy', 'bread', 'breadcrumbs', 'breakfast', 'brie', 'brine',\n",
      "       'brisket', 'broccoli', 'broccoli rabe', 'broil', 'brooklyn',\n",
      "       'brown rice', 'brownie', 'brunch', 'brussel sprout', 'buffalo',\n",
      "       'buffet', 'bulgaria', 'bulgur', 'burrito', 'butter', 'buttermilk',\n",
      "       'butternut squash', 'butterscotch/caramel', 'cabbage', 'cake',\n",
      "       'california', 'calvados', 'cambridge', 'campari', 'camping', 'canada',\n",
      "       'candy', 'candy thermometer', 'cantaloupe', 'capers', 'caraway',\n",
      "       'cardamom', 'carrot', 'cashew', 'casserole/gratin', 'cauliflower',\n",
      "       'caviar', 'celery', 'chambord', 'champagne', 'chard', 'chartreuse',\n",
      "       'cheddar', 'cheese', 'cherry', 'chestnut', 'chicago', 'chicken',\n",
      "       'chickpea', 'chile', 'chile pepper', 'chili', 'chill', 'chive',\n",
      "       'chocolate', 'christmas', 'christmas eve', 'cilantro', 'cinco de mayo',\n",
      "       'cinnamon', 'citrus', 'clam', 'clove', 'cobbler/crumble', 'cocktail',\n",
      "       'cocktail party', 'coconut', 'cod', 'coffee', 'coffee grinder',\n",
      "       'cognac/armagnac', 'collard greens', 'colorado', 'columbus',\n",
      "       'condiment', 'condiment/spread', 'connecticut', 'cook like a diner',\n",
      "       'cookbook critic', 'cookie', 'cookies', 'coriander', 'corn', 'cornmeal',\n",
      "       'costa mesa', 'cottage cheese', 'couscous', 'crab', 'cranberry',\n",
      "       'cranberry sauce', 'cream cheese', 'créme de cacao', 'crêpe',\n",
      "       'cr��me de cacao', 'cuba', 'cucumber', 'cumin', 'cupcake', 'currant',\n",
      "       'curry', 'custard', 'dairy', 'dairy free', 'dallas', 'date', 'deep-fry',\n",
      "       'denver', 'dessert', 'digestif', 'dill', 'dinner', 'dip', 'diwali',\n",
      "       'dominican republic', 'dorie greenspan', 'double boiler', 'dried fruit',\n",
      "       'drink', 'drinks', 'duck', 'easter', 'eau de vie', 'edible gift', 'egg',\n",
      "       'egg nog', 'eggplant', 'egypt', 'emeril lagasse', 'endive',\n",
      "       'engagement party', 'england', 'entertaining', 'epi + ushg',\n",
      "       'epi loves the microwave', 'escarole', 'fall', 'family reunion',\n",
      "       'fat free', 'father's day', 'fennel', 'feta', 'fig', 'fish',\n",
      "       'flaming hot summer', 'flat bread', 'florida', 'fontina',\n",
      "       'food processor', 'fortified wine', 'fourth of july', 'france',\n",
      "       'frangelico', 'frankenrecipe', 'freeze/chill', 'freezer food',\n",
      "       'friendsgiving', 'frittata', 'fritter', 'frozen dessert', 'fruit',\n",
      "       'fruit juice', 'fry', 'game', 'garlic', 'georgia', 'germany', 'gin',\n",
      "       'ginger', 'goat cheese', 'goose', 'gouda', 'gourmet', 'graduation',\n",
      "       'grains', 'grand marnier', 'granola', 'grape', 'grapefruit', 'grappa',\n",
      "       'green bean', 'green onion/scallion', 'grill', 'grill/barbecue',\n",
      "       'ground beef', 'ground lamb', 'guam', 'guava', 'haiti', 'halibut',\n",
      "       'halloween', 'ham', 'hamburger', 'hanukkah', 'harpercollins', 'hawaii',\n",
      "       'hazelnut', 'healdsburg', 'healthy', 'herb', 'high fiber', 'hollywood',\n",
      "       'hominy/cornmeal/masa', 'honey', 'honeydew', 'hors d'oeuvre',\n",
      "       'horseradish', 'hot drink', 'hot pepper', 'house & garden',\n",
      "       'house cocktail', 'houston', 'hummus', 'ice cream', 'ice cream machine',\n",
      "       'iced coffee', 'iced tea', 'idaho', 'illinois', 'indiana', 'iowa',\n",
      "       'ireland', 'israel', 'italy', 'jalapeño', 'jam or jelly', 'jamaica',\n",
      "       'japan', 'jerusalem artichoke', 'juicer', 'jícama', 'kahlúa', 'kale',\n",
      "       'kansas', 'kansas city', 'kentucky', 'kentucky derby', 'kid-friendly',\n",
      "       'kidney friendly', 'kirsch', 'kitchen olympics', 'kiwi', 'kosher',\n",
      "       'kosher for passover', 'kumquat', 'kwanzaa', 'labor day', 'lamb',\n",
      "       'lamb chop', 'lamb shank', 'lancaster', 'las vegas', 'lasagna',\n",
      "       'leafy green', 'leek', 'legume', 'lemon', 'lemon juice', 'lemongrass',\n",
      "       'lentil', 'lettuce', 'lima bean', 'lime', 'lime juice', 'lingonberry',\n",
      "       'liqueur', 'lobster', 'london', 'long beach', 'los angeles',\n",
      "       'louisiana', 'louisville', 'low cal', 'low carb', 'low cholesterol',\n",
      "       'low fat', 'low sodium', 'low sugar', 'low/no sugar', 'lunar new year',\n",
      "       'lunch', 'lychee', 'macadamia nut', 'macaroni and cheese', 'maine',\n",
      "       'mandoline', 'mango', 'maple syrup', 'mardi gras', 'margarita',\n",
      "       'marinade', 'marinate', 'marsala', 'marscarpone', 'marshmallow',\n",
      "       'martini', 'maryland', 'massachusetts', 'mayonnaise', 'meat',\n",
      "       'meatball', 'meatloaf', 'melon', 'mexico', 'mezcal', 'miami',\n",
      "       'michigan', 'microwave', 'midori', 'milk/cream', 'minneapolis',\n",
      "       'minnesota', 'mint', 'mississippi', 'missouri', 'mixer', 'molasses',\n",
      "       'monterey jack', 'mortar and pestle', 'mother's day', 'mozzarella',\n",
      "       'muffin', 'mushroom', 'mussel', 'mustard', 'mustard greens',\n",
      "       'nancy silverton', 'nebraska', 'nectarine', 'new hampshire',\n",
      "       'new jersey', 'new mexico', 'new orleans', 'new year's day',\n",
      "       'new year's eve', 'new york', 'no meat, no problem', 'no sugar added',\n",
      "       'no-cook', 'non-alcoholic', 'noodle', 'north carolina', 'nut', 'nutmeg',\n",
      "       'oat', 'oatmeal', 'octopus', 'ohio', 'oklahoma', 'okra', 'oktoberfest',\n",
      "       'olive', 'omelet', 'one-pot meal', 'onion', 'orange', 'orange juice',\n",
      "       'oregano', 'oregon', 'organic', 'orzo', 'oscars', 'oyster',\n",
      "       'pacific palisades', 'paleo', 'pan-fry', 'pancake', 'papaya', 'paprika',\n",
      "       'parade', 'paris', 'parmesan', 'parsley', 'parsnip', 'party',\n",
      "       'pasadena', 'passion fruit', 'passover', 'pasta', 'pasta maker',\n",
      "       'pastry', 'pea', 'peach', 'peanut', 'peanut butter', 'peanut free',\n",
      "       'pear', 'pecan', 'pennsylvania', 'pepper', 'pernod', 'persian new year',\n",
      "       'persimmon', 'peru', 'pescatarian', 'philippines',\n",
      "       'phyllo/puff pastry dough', 'pickles', 'picnic', 'pie', 'pine nut',\n",
      "       'pineapple', 'pistachio', 'pittsburgh', 'pizza', 'plantain', 'plum',\n",
      "       'poach', 'poblano', 'poker/game night', 'pomegranate',\n",
      "       'pomegranate juice', 'poppy', 'pork', 'pork chop', 'pork rib',\n",
      "       'pork tenderloin', 'port', 'portland', 'pot pie', 'potato',\n",
      "       'potato salad', 'potluck', 'poultry', 'poultry sausage',\n",
      "       'pressure cooker', 'prosciutto', 'providence', 'prune', 'pumpkin',\n",
      "       'punch', 'purim', 'quail', 'quiche', 'quick & easy',\n",
      "       'quick and healthy', 'quince', 'quinoa', 'rabbit', 'rack of lamb',\n",
      "       'radicchio', 'radish', 'raisin', 'ramadan', 'ramekin', 'raspberry',\n",
      "       'raw', 'red wine', 'rhode island', 'rhubarb', 'rice', 'ricotta',\n",
      "       'roast', 'root vegetable', 'rosemary', 'rosh hashanah/yom kippur',\n",
      "       'rosé', 'rub', 'rum', 'rutabaga', 'rye', 'saffron', 'sage', 'sake',\n",
      "       'salad', 'salad dressing', 'salmon', 'salsa', 'san francisco',\n",
      "       'sandwich', 'sandwich theory', 'sangria', 'santa monica', 'sardine',\n",
      "       'sauce', 'sausage', 'sauté', 'scallop', 'scotch', 'seafood', 'seattle',\n",
      "       'seed', 'self', 'semolina', 'sesame', 'sesame oil', 'shallot',\n",
      "       'shavuot', 'shellfish', 'sherry', 'shower', 'shrimp', 'side', 'simmer',\n",
      "       'skewer', 'slow cooker', 'smoker', 'smoothie', 'snapper', 'sorbet',\n",
      "       'soufflé/meringue', 'soup/stew', 'sour cream', 'sourdough',\n",
      "       'south carolina', 'soy', 'soy free', 'soy sauce', 'spain',\n",
      "       'sparkling wine', 'spice', 'spinach', 'spirit', 'spring', 'spritzer',\n",
      "       'squash', 'squid', 'st. louis', 'st. patrick's day', 'steak', 'steam',\n",
      "       'stew', 'stir-fry', 'stock', 'strawberry', 'stuffing/dressing',\n",
      "       'sugar conscious', 'sugar snap pea', 'sukkot', 'summer', 'super bowl',\n",
      "       'suzanne goin', 'sweet potato/yam', 'swiss cheese', 'switzerland',\n",
      "       'swordfish', 'taco', 'tailgating', 'tamarind', 'tangerine', 'tapioca',\n",
      "       'tarragon', 'tart', 'tea', 'tennessee', 'tequila', 'tested & improved',\n",
      "       'texas', 'thanksgiving', 'thyme', 'tilapia', 'tofu', 'tomatillo',\n",
      "       'tomato', 'tortillas', 'tree nut', 'tree nut free', 'triple sec',\n",
      "       'tropical fruit', 'trout', 'tuna', 'turnip', 'utah', 'valentine's day',\n",
      "       'vanilla', 'veal', 'vegan', 'vegetable', 'vegetarian', 'venison',\n",
      "       'vermont', 'vermouth', 'vinegar', 'virginia', 'vodka', 'waffle',\n",
      "       'walnut', 'wasabi', 'washington', 'washington, d.c.', 'watercress',\n",
      "       'watermelon', 'wedding', 'weelicious', 'west virginia', 'westwood',\n",
      "       'wheat/gluten-free', 'whiskey', 'white wine', 'whole wheat',\n",
      "       'wild rice', 'windsor', 'wine', 'winter', 'wisconsin', 'wok',\n",
      "       'yellow squash', 'yogurt', 'yonkers', 'yuca', 'zucchini', 'cookbooks',\n",
      "       'leftovers', 'snack', 'snack week', 'turkey'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Examine the fields that are present in the data\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: A lot of the columns are not going to be relevant to the analysis because they are not ingredients. From observation here are the key categories of \"dirty data\": <br>\n",
    "1) Hashtags (starting with \"#\") <br>\n",
    "2) Text containing numeric symbols ('22-minute meals', '3-ingredient recipes') <br>\n",
    "3) Places (Country names, state names, city names) <br>\n",
    "4) Events (e.g. cinco de mayo, christmas eve) <br>\n",
    "\n",
    "One quick way to eliminate these dirty data is to use Named Entity Recognition under the spacy package, which is done in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('30 days', 'DATE')], [('alabama', 'GPE')], [('alaska', 'GPE')], [('anthony bourdain', 'PERSON')], [('apple', 'ORG')], [('apple juice', 'ORG')], [('arizona', 'GPE')], [('arugula', 'PERSON')], [('asian', 'NORP')], [('atlanta', 'GPE')], [('australia', 'GPE')], [('avocado', 'ORG')], [('backyard bbq', 'PERSON')], [('bastille day', 'ORG')], [('bell', 'ORG')], [('beverly hills', 'GPE')], [('blueberry', 'PERSON')], [('bon appétit', 'PERSON')], [('bon app', 'PERSON')], [('boston', 'GPE')], [('broccoli rabe', 'ORG')], [('brooklyn', 'GPE')], [('brown rice', 'PERSON')], [('bulgaria', 'GPE')], [('burrito', 'PERSON')], [('california', 'GPE')], [('cambridge', 'GPE')], [('canada', 'GPE')], [('candy thermometer', 'PERSON')], [('chicago', 'GPE')], [('chili', 'GPE')], [('christmas', 'DATE')], [('christmas eve', 'DATE')], [('cilantro', 'GPE')], [('cinco de mayo', 'PERSON')], [('collard greens', 'PERSON')], [('colorado', 'GPE')], [('columbus', 'ORG')], [('connecticut', 'GPE')], [('costa mesa', 'ORG')], [('créme de cacao', 'PERSON')], [('de cacao', 'PERSON')], [('cuba', 'GPE')], [('cucumber', 'PERSON')], [('dallas', 'GPE')], [('denver', 'GPE')], [('diwali', 'PERSON')], [('dominican republic', 'ORG')], [('dorie greenspan', 'PERSON')], [('eau de vie', 'PERSON')], [('egypt', 'GPE')], [('emeril lagasse', 'ORG')], [('england', 'PERSON')], [('florida', 'GPE')], [('fourth of july', 'DATE')], [('france', 'GPE')], [('frozen dessert', 'PERSON')], [('fry', 'ORG')], [('georgia', 'GPE')], [('germany', 'GPE')], [('goat cheese', 'PERSON')], [('gouda', 'ORG')], [('grand marnier', 'PERSON')], [('grappa', 'PERSON')], [('grill/barbecue', 'ORG')], [('halloween', 'DATE')], [('hawaii', 'GPE')], [('healdsburg', 'GPE')], [('hollywood', 'GPE')], [('hominy/cornmeal/masa', 'ORG')], [('house & garden', 'ORG')], [('house', 'ORG')], [('houston', 'GPE')], [('idaho', 'GPE')], [('illinois', 'GPE')], [('indiana', 'GPE')], [('iowa', 'GPE')], [('ireland', 'GPE')], [('israel', 'GPE')], [('italy', 'GPE')], [('jam', 'ORG')], [('jamaica', 'GPE')], [('japan', 'GPE')], [('jerusalem', 'GPE')], [('jícama', 'PERSON')], [('kansas', 'GPE')], [('kansas', 'GPE')], [('kentucky', 'GPE')], [('kentucky', 'GPE')], [('kirsch', 'ORG')], [('kwanzaa', 'PERSON')], [('lamb chop', 'PERSON')], [('lamb shank', 'PERSON')], [('las vegas', 'GPE')], [('leafy green', 'PERSON')], [('lima bean', 'ORG')], [('london', 'GPE')], [('los angeles', 'GPE')], [('louisiana', 'GPE')], [('louisville', 'GPE')], [('lunar new year', 'EVENT')], [('lychee', 'ORG')], [('macadamia nut', 'PERSON')], [('maine', 'GPE')], [('mardi gras', 'PERSON')], [('maryland', 'GPE')], [('massachusetts', 'GPE')], [('mexico', 'GPE')], [('miami', 'GPE')], [('michigan', 'GPE')], [('minneapolis', 'GPE')], [('minnesota', 'GPE')], [('mississippi', 'PERSON')], [('missouri', 'GPE')], [('monterey jack', 'PERSON')], [('mortar', 'ORG')], [(\"mother's day\", 'DATE')], [('mozzarella', 'PERSON')], [('mustard greens', 'PERSON')], [('nancy silverton', 'PERSON')], [('nebraska', 'ORG')], [('nectarine', 'PERSON')], [('new jersey', 'GPE')], [(\"new year's day\", 'DATE')], [(\"new year's eve\", 'DATE')], [('new york', 'GPE')], [('north carolina', 'GPE')], [('nut', 'ORG')], [('ohio', 'GPE')], [('oklahoma', 'GPE')], [('one', 'CARDINAL')], [('orange juice', 'ORG')], [('oregano', 'ORG')], [('oregon', 'GPE')], [('pacific', 'ORG')], [('paleo', 'ORG')], [('pan-fry', 'PERSON')], [('paris', 'GPE')], [('peanut', 'PERSON')], [('peanut', 'PERSON')], [('peanut free', 'PERSON')], [('pennsylvania', 'GPE')], [('persian new year', 'EVENT')], [('peru', 'GPE')], [('philippines', 'GPE')], [('pistachio', 'ORG')], [('pittsburgh', 'GPE')], [('prosciutto', 'ORG')], [('quick & easy', 'ORG')], [('quinoa', 'PERSON')], [('radicchio', 'GPE')], [('rhode island', 'GPE')], [('san francisco', 'GPE')], [('santa monica', 'PERSON')], [('sauté', 'ORG')], [('scallop', 'ORG')], [('seattle', 'ORG')], [('semolina', 'GPE')], [('sorbet', 'PERSON')], [('soufflé/meringue', 'ORG')], [('south carolina', 'GPE')], [('spain', 'GPE')], [('spritzer', 'PERSON')], [('st.', 'GPE')], [(\"st. patrick's\", 'ORG')], [('sukkot', 'PERSON')], [('suzanne goin', 'PERSON')], [('sweet potato/yam', 'PERSON')], [('swiss', 'NORP')], [('switzerland', 'GPE')], [('tennessee', 'GPE')], [('tested & improved', 'ORG')], [('texas', 'GPE')], [('thanksgiving', 'DATE')], [('tree nut', 'PERSON')], [('tree nut free', 'PERSON')], [('sec', 'ORG')], [('utah', 'GPE')], [(\"valentine's day\", 'EVENT')], [('venison', 'PERSON')], [('vermont', 'GPE')], [('vermouth', 'PERSON')], [('virginia', 'GPE')], [('washington', 'GPE')], [('washington', 'GPE'), ('d.c', 'GPE')], [('west virginia', 'GPE')], [('winter', 'DATE')], [('wisconsin', 'GPE')], [('zucchini', 'PERSON')], [('snack week', 'DATE')], [('turkey', 'GPE')]]\n"
     ]
    }
   ],
   "source": [
    "# Using Named Entity Recognition to easily tag irrelevant terms \n",
    "# Subset all the relevant columns candidate for ingredient list i.e. eliminate the first few columns\n",
    "pos_ingr = df.drop(columns=['title', 'rating', 'calories', 'protein', 'fat', 'sodium'], axis=1).columns\n",
    "\n",
    "# Create a function that outputs a list of tuples containing the entity and the NER tag\n",
    "def ner_tag(word):\n",
    "    doc = nlp(word)\n",
    "    ne = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return ne\n",
    "\n",
    "filter = ['DATE', 'GPE', 'NORP']\n",
    "filter_set = set(filter)\n",
    "\n",
    "ner_list = [ner_tag(ner) for ner in pos_ingr if len(ner_tag(ner)) is not 0]\n",
    "print(ner_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally not a clean classification result, but the model is pretty good in identifying DATE, GPE (Geopolitical Entities), and NORP (Nationalities). The next step is to start isolating these types of entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30 days',\n",
       " 'alabama',\n",
       " 'alaska',\n",
       " 'arizona',\n",
       " 'asian',\n",
       " 'atlanta',\n",
       " 'australia',\n",
       " 'beverly hills',\n",
       " 'boston',\n",
       " 'brooklyn',\n",
       " 'bulgaria',\n",
       " 'california',\n",
       " 'cambridge',\n",
       " 'canada',\n",
       " 'chicago',\n",
       " 'chili',\n",
       " 'christmas',\n",
       " 'christmas eve',\n",
       " 'cilantro',\n",
       " 'colorado',\n",
       " 'connecticut',\n",
       " 'cuba',\n",
       " 'dallas',\n",
       " 'denver',\n",
       " 'egypt',\n",
       " 'florida',\n",
       " 'fourth of july',\n",
       " 'france',\n",
       " 'georgia',\n",
       " 'germany',\n",
       " 'halloween',\n",
       " 'hawaii',\n",
       " 'healdsburg',\n",
       " 'hollywood',\n",
       " 'houston',\n",
       " 'idaho',\n",
       " 'illinois',\n",
       " 'indiana',\n",
       " 'iowa',\n",
       " 'ireland',\n",
       " 'israel',\n",
       " 'italy',\n",
       " 'jamaica',\n",
       " 'japan',\n",
       " 'jerusalem',\n",
       " 'kansas',\n",
       " 'kansas',\n",
       " 'kentucky',\n",
       " 'kentucky',\n",
       " 'las vegas',\n",
       " 'london',\n",
       " 'los angeles',\n",
       " 'louisiana',\n",
       " 'louisville',\n",
       " 'maine',\n",
       " 'maryland',\n",
       " 'massachusetts',\n",
       " 'mexico',\n",
       " 'miami',\n",
       " 'michigan',\n",
       " 'minneapolis',\n",
       " 'minnesota',\n",
       " 'missouri',\n",
       " \"mother's day\",\n",
       " 'new jersey',\n",
       " \"new year's day\",\n",
       " \"new year's eve\",\n",
       " 'new york',\n",
       " 'north carolina',\n",
       " 'ohio',\n",
       " 'oklahoma',\n",
       " 'oregon',\n",
       " 'paris',\n",
       " 'pennsylvania',\n",
       " 'peru',\n",
       " 'philippines',\n",
       " 'pittsburgh',\n",
       " 'radicchio',\n",
       " 'rhode island',\n",
       " 'san francisco',\n",
       " 'semolina',\n",
       " 'south carolina',\n",
       " 'spain',\n",
       " 'st.',\n",
       " 'swiss',\n",
       " 'switzerland',\n",
       " 'tennessee',\n",
       " 'texas',\n",
       " 'thanksgiving',\n",
       " 'utah',\n",
       " 'vermont',\n",
       " 'virginia',\n",
       " 'washington',\n",
       " 'washington',\n",
       " 'west virginia',\n",
       " 'winter',\n",
       " 'wisconsin',\n",
       " 'snack week',\n",
       " 'turkey']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = ['DATE', 'GPE', 'NORP']\n",
    "filter_set = set(filter)\n",
    "ner_filtered = [tup[0][0] for tup in ner_list if tup[0][1] in filter_set]\n",
    "ner_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the list by removing obviously relevant terms which were excluded:\n",
    "relevant = ['turkey','cilantro','radicchio','semolina']\n",
    "ner_filtered = [e for e in ner_filtered if e not in relevant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to isolate the other irrelevant terms using pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Isolate hashtags and words with numeric symbols\n",
    "hashtag_num_filtered = list(pos_ingr[pos_ingr.str.contains('[#0-9]', regex=True)])\n",
    "\n",
    "# Combine the lists of irrelevant keywords\n",
    "irrelevant_filtered = list(set(list(ner_filtered + hashtag_num_filtered)))\n",
    "\n",
    "# Final list of \"relevant\" keywords\n",
    "relevant_filtered = [e for e in pos_ingr if e not in irrelevant_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now subset the columns with the keywords that we believe are most likely \"ingredients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['title', 'rating', 'calories', 'protein', 'fat', 'sodium'] + relevant_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding that the cleaning procedure might not have removed all the dirty keywords in the process, we do a final cleaning effort by looking at the dirty keywords with a lot of observations. <br>\n",
    "In the interest of time, we'll look at the top 100 keywords and pick the obvious irrelevant ones and manually remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bon appétit          8654\n",
       "peanut free          7698\n",
       "soy free             7415\n",
       "tree nut free        6425\n",
       "vegetarian           6168\n",
       "gourmet              5950\n",
       "kosher               5621\n",
       "pescatarian          5508\n",
       "quick & easy         4853\n",
       "wheat/gluten-free    4446\n",
       "bake                 4109\n",
       "summer               3845\n",
       "dessert              3234\n",
       "dairy free           2901\n",
       "no sugar added       2843\n",
       "side                 2776\n",
       "fall                 2751\n",
       "dinner               2555\n",
       "sugar conscious      2218\n",
       "healthy              2192\n",
       "kidney friendly      2015\n",
       "onion                2003\n",
       "tomato               2002\n",
       "vegetable            1929\n",
       "sauté                1926\n",
       "milk/cream           1841\n",
       "fruit                1833\n",
       "kid-friendly         1681\n",
       "egg                  1639\n",
       "vegan                1586\n",
       "spring               1571\n",
       "herb                 1531\n",
       "garlic               1477\n",
       "salad                1454\n",
       "dairy                1369\n",
       "appetizer            1315\n",
       "lunch                1294\n",
       "cheese               1292\n",
       "chicken              1272\n",
       "roast                1183\n",
       "cocktail party       1099\n",
       "soup/stew            1081\n",
       "drink                1064\n",
       "no-cook              1061\n",
       "potato               1053\n",
       "ginger               1050\n",
       "chill                1024\n",
       "grill/barbecue       1021\n",
       "lemon                1019\n",
       "high fiber            975\n",
       "low cal               956\n",
       "pasta                 939\n",
       "fish                  892\n",
       "food processor        885\n",
       "pork                  880\n",
       "leafy green           864\n",
       "low fat               844\n",
       "backyard bbq          844\n",
       "nut                   838\n",
       "party                 837\n",
       "alcoholic             823\n",
       "mushroom              800\n",
       "brunch                799\n",
       "orange                789\n",
       "chocolate             783\n",
       "citrus                780\n",
       "simmer                762\n",
       "beef                  756\n",
       "sauce                 751\n",
       "condiment/spread      725\n",
       "bell pepper           716\n",
       "paleo                 697\n",
       "breakfast             684\n",
       "cake                  677\n",
       "carrot                636\n",
       "parmesan              622\n",
       "apple                 622\n",
       "spice                 613\n",
       "mixer                 578\n",
       "poultry               573\n",
       "mint                  569\n",
       "vinegar               564\n",
       "marinate              562\n",
       "bacon                 557\n",
       "pepper                554\n",
       "blender               553\n",
       "bean                  552\n",
       "cilantro              549\n",
       "almond                548\n",
       "mustard               543\n",
       "shellfish             534\n",
       "basil                 531\n",
       "olive                 525\n",
       "grill                 513\n",
       "lime                  505\n",
       "yogurt                494\n",
       "shrimp                489\n",
       "picnic                485\n",
       "rice                  478\n",
       "parsley               463\n",
       "potluck               459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['title', 'rating', 'calories', 'protein', 'fat', 'sodium']).sum(axis=0).sort_values(ascending=False)[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dirty_list = ['bon appétit', 'peanut free', 'soy free', 'tree nut free', 'vegetarian', 'gourmet', 'kosher', \n",
    "                    'pescatarian', 'quick & easy', 'wheat/gluten-free', 'bake', 'summer', 'dessert', 'dairy free', \n",
    "                    'side', 'no sugar added', 'fall', 'dinner', 'sugar conscious', 'healthy', 'kidney friendly',\n",
    "                    'vegetable', 'sauté' , 'fruit', 'vegan', 'kid-friendly', 'spring', 'herb', 'salad', 'dairy', \n",
    "                    'appetizer', 'lunch', 'roast', 'no-cook', 'soup/stew', 'cocktail party', 'chill', 'grill/barbecue',\n",
    "                    'drink', 'sauce', 'low cal', 'high fiber', 'food processor','backyard bbq','low fat', 'condiment/spread',     \n",
    "                    'party', 'simmer', 'alcoholic','brunch', 'paleo', 'cake', 'breakfast', 'spice', 'mixer', 'poultry',\n",
    "                    'citrus', 'blender', 'marinate', 'grill', 'picnic'] \n",
    "\n",
    "df = df.drop(columns = final_dirty_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering the Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What ingredient has the highest probability of the recipe having a high calorie content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this, we first look at the distribution of calories. Just by looking at the descriptive statistics we can already see outliers in the data (the highest caloric content is 30M calories). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.450200e+04\n",
       "mean     6.622096e+03\n",
       "std      3.747819e+05\n",
       "min      0.000000e+00\n",
       "25%      2.050000e+02\n",
       "50%      3.450000e+02\n",
       "75%      5.990000e+02\n",
       "max      3.011122e+07\n",
       "Name: calories, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['calories'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>advance prep required</th>\n",
       "      <th>almond</th>\n",
       "      <th>amaretto</th>\n",
       "      <th>anchovy</th>\n",
       "      <th>...</th>\n",
       "      <th>wok</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11391</th>\n",
       "      <td>Pear-Cranberry Mincemeat Lattice Pie</td>\n",
       "      <td>4.375</td>\n",
       "      <td>30111218.0</td>\n",
       "      <td>200968.0</td>\n",
       "      <td>1722763.0</td>\n",
       "      <td>27675110.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>Deep-Dish Wild Blueberry Pie</td>\n",
       "      <td>4.375</td>\n",
       "      <td>29997918.0</td>\n",
       "      <td>200210.0</td>\n",
       "      <td>1716279.0</td>\n",
       "      <td>27570999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>Apricot, Cranberry and Walnut Pie</td>\n",
       "      <td>4.375</td>\n",
       "      <td>13062948.0</td>\n",
       "      <td>87188.0</td>\n",
       "      <td>747374.0</td>\n",
       "      <td>12005810.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>Lamb Köfte with Tarator Sauce</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4518216.0</td>\n",
       "      <td>166471.0</td>\n",
       "      <td>44198.0</td>\n",
       "      <td>7540990.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Rice Pilaf with Lamb, Carrots, and Raisins</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4157357.0</td>\n",
       "      <td>236489.0</td>\n",
       "      <td>221495.0</td>\n",
       "      <td>3134853.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 527 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  rating    calories  \\\n",
       "11391        Pear-Cranberry Mincemeat Lattice Pie    4.375  30111218.0   \n",
       "6368                 Deep-Dish Wild Blueberry Pie    4.375  29997918.0   \n",
       "19672           Apricot, Cranberry and Walnut Pie    4.375  13062948.0   \n",
       "2976                Lamb Köfte with Tarator Sauce    5.000   4518216.0   \n",
       "1304   Rice Pilaf with Lamb, Carrots, and Raisins    5.000   4157357.0   \n",
       "\n",
       "        protein        fat      sodium  advance prep required  almond  \\\n",
       "11391  200968.0  1722763.0  27675110.0                      0       0   \n",
       "6368   200210.0  1716279.0  27570999.0                      0       0   \n",
       "19672   87188.0   747374.0  12005810.0                      0       0   \n",
       "2976   166471.0    44198.0   7540990.0                      0       0   \n",
       "1304   236489.0   221495.0   3134853.0                      0       0   \n",
       "\n",
       "       amaretto  anchovy  ...  wok  yellow squash  yogurt  yonkers  yuca  \\\n",
       "11391         0        0  ...    0              0       0        0     0   \n",
       "6368          0        0  ...    0              0       0        0     0   \n",
       "19672         0        0  ...    0              0       0        0     0   \n",
       "2976          0        0  ...    0              0       0        0     0   \n",
       "1304          0        0  ...    0              0       0        0     0   \n",
       "\n",
       "       zucchini  cookbooks  leftovers  snack  turkey  \n",
       "11391         0          0          0      0       0  \n",
       "6368          0          0          0      0       0  \n",
       "19672         0          0          0      0       0  \n",
       "2976          0          0          0      0       0  \n",
       "1304          0          0          0      0       0  \n",
       "\n",
       "[5 rows x 527 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['calories'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll define a function that will remove outliers using the Tukey Rule, and then filter out the outliers from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13587.000000\n",
       "mean       390.475086\n",
       "std        257.387981\n",
       "min          1.000000\n",
       "25%        197.500000\n",
       "50%        322.000000\n",
       "75%        538.000000\n",
       "max       1188.000000\n",
       "Name: calories, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tukey_rule(data_frame, column_name):\n",
    "    df_column = data_frame[column_name]\n",
    "    Q1 = df_column.quantile(0.25)\n",
    "    Q3 = df_column.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    max_value = Q3 + 1.5 * IQR\n",
    "    min_value = Q1 - 1.5 * IQR\n",
    "    df_no_outliers = data_frame[(data_frame[column_name] < max_value) & (data_frame[column_name] > min_value)]\n",
    "    return df_no_outliers\n",
    "\n",
    "df_calorie_analysis = tukey_rule(df, 'calories')\n",
    "\n",
    "# Check the descriptive statistics with the outliers removed:\n",
    "df_calorie_analysis[df_calorie_analysis['calories'] != 0]['calories'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to answer the research question by getting the mean calorie level per ingredient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crêpe                      1168.000000\n",
       "mortar and pestle          1006.000000\n",
       "westwood                    934.000000\n",
       "new orleans                 898.000000\n",
       "kitchen olympics            898.000000\n",
       "epi loves the microwave     891.000000\n",
       "pot pie                     843.000000\n",
       "brisket                     837.105263\n",
       "lamb shank                  828.250000\n",
       "pork rib                    826.125000\n",
       "grains                      812.600000\n",
       "lamb chop                   789.478261\n",
       "flat bread                  753.000000\n",
       "rack of lamb                741.300000\n",
       "tart                        739.500000\n",
       "anthony bourdain            732.500000\n",
       "guam                        732.000000\n",
       "nancy silverton             718.000000\n",
       "game                        717.909091\n",
       "lamb                        717.829787\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calorie_vector = df_calorie_analysis['calories']\n",
    "df_calorie_analysis = df_calorie_analysis.drop(columns = ['title', 'rating', 'calories', 'protein', 'fat', 'sodium'], axis=1)\n",
    "\n",
    "# Multiply all the columns of 1 and 0 with the calorie array\n",
    "df_calorie_analysis = df_calorie_analysis.mul(df_calorie_vector, axis=0)\n",
    "\n",
    "# Replace all 0's with NAs so that they would not affect the computation of averages\n",
    "cols = df_calorie_analysis.columns\n",
    "df_calorie_analysis[cols] = df_calorie_analysis[cols].replace({0:np.nan})\n",
    "\n",
    "# Get the mean across rows\n",
    "df_calorie_analysis.mean(axis=0, skipna=True).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the top keywords are irrelevant but looking at the top 20 we can see that these tend to have high caloric content:\n",
    "\n",
    "1) crêpe <br> \n",
    "2) brisket <br>\n",
    "3) lamb shank <br>\n",
    "4) pork rib <br>\n",
    "5) flat bread <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What ingredients are most important to a high rating for a recipe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is looking at the ratings distribution and dealing with the missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16592.000000\n",
       "mean         4.085403\n",
       "std          0.663389\n",
       "min          1.250000\n",
       "25%          3.750000\n",
       "50%          4.375000\n",
       "75%          4.375000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out the missing values and 0's for Rating\n",
    "df_rating = df[pd.notnull(df['rating'])]\n",
    "df_rating = df[df['rating'] != 0]\n",
    "df_rating['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to what I did for calories, I computed for the mean rating per ingredient and pulled up the top ingredients with the highest average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mortar and pestle    5.000000\n",
       "flat bread           5.000000\n",
       "suzanne goin         5.000000\n",
       "sourdough            5.000000\n",
       "cookbook critic      5.000000\n",
       "cupcake              5.000000\n",
       "custard              5.000000\n",
       "emeril lagasse       5.000000\n",
       "sardine              5.000000\n",
       "brownie              5.000000\n",
       "rub                  5.000000\n",
       "burrito              5.000000\n",
       "pickles              5.000000\n",
       "yonkers              5.000000\n",
       "juicer               4.791667\n",
       "granola              4.687500\n",
       "grappa               4.687500\n",
       "omelet               4.687500\n",
       "soufflé/meringue     4.687500\n",
       "lychee               4.687500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_vector = df_rating['rating']\n",
    "df_rating = df_rating.drop(columns = ['title', 'rating', 'calories', 'protein', 'fat', 'sodium'], axis=1)\n",
    "\n",
    "# Multiply all the columns of 1 and 0 with the rating array\n",
    "df_rating = df_rating.mul(df_rating_vector, axis=0)\n",
    "\n",
    "# Replace all 0's with NAs so that they would not affect the computation of averages\n",
    "cols = df_rating.columns\n",
    "df_rating[cols] = df_rating[cols].replace({0:np.nan})\n",
    "\n",
    "# Get the mean across rows\n",
    "df_rating.mean(axis=0, skipna=True).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top ingredients from dishes with the highest average rating:\n",
    "\n",
    "1) flat bread \n",
    "2) sourdough\n",
    "3) cupcake\n",
    "4) custard\n",
    "5) sardine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)  If I typically enjoy high protein to fat ratio, which recipes should I try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove the outliers for both protein and fat metrics using the function that we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11627.000000\n",
       "mean        15.406296\n",
       "std         15.605555\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          9.000000\n",
       "75%         23.000000\n",
       "max         71.000000\n",
       "Name: protein, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_fat_analysis = df[(df['protein'] != 0) & (df['fat'] != 0) & (pd.notnull(df['protein'])) & (pd.notnull(df['fat']))]\n",
    "\n",
    "df_protein_fat_analysis = tukey_rule(df_protein_fat_analysis, 'protein')\n",
    "df_protein_fat_analysis = tukey_rule(df_protein_fat_analysis, 'fat')\n",
    "\n",
    "# Check the descriptive statistics with the outliers removed:\n",
    "df_protein_fat_analysis['protein'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11627.000000\n",
       "mean        20.673347\n",
       "std         14.726497\n",
       "min          1.000000\n",
       "25%          9.000000\n",
       "50%         17.000000\n",
       "75%         29.000000\n",
       "max         64.000000\n",
       "Name: fat, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_fat_analysis['fat'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the outliers are removed, I can now compute for the protein to fat ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11627.000000\n",
       "mean         0.951939\n",
       "std          1.210858\n",
       "min          0.016393\n",
       "25%          0.306624\n",
       "50%          0.631579\n",
       "75%          1.125000\n",
       "max         30.000000\n",
       "Name: protein_fat_ratio, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_fat_analysis['protein_fat_ratio'] = df_protein_fat_analysis['protein'] / df_protein_fat_analysis['fat']\n",
    "df_protein_fat_analysis['protein_fat_ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following recipes have the highest protein to fat ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>protein_fat_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13867</th>\n",
       "      <td>Fish and Yuca Stew with Pickled Onions</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855</th>\n",
       "      <td>Lobster Gelees with Fresh Tarragon Oil</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Fish Mixed Grill</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18646</th>\n",
       "      <td>Sweet and Sour Crab Salad</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9266</th>\n",
       "      <td>Scallop, Shrimp, and Squid \"Ceviche\"</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  protein_fat_ratio\n",
       "13867  Fish and Yuca Stew with Pickled Onions                30.0\n",
       "10855  Lobster Gelees with Fresh Tarragon Oil                27.5\n",
       "281                          Fish Mixed Grill                22.5\n",
       "18646               Sweet and Sour Crab Salad                22.0\n",
       "9266     Scallop, Shrimp, and Squid \"Ceviche\"                16.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_protein_fat_analysis.sort_values(by =['protein_fat_ratio'], ascending=False)[['title','protein_fat_ratio']][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) If you had to pick 10 recipes to recommend based on this data, what would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that there are two important metrics to look at to answer this question: ratings and calorie count. It's great to have a low-calorie meal that's well-reviewed (meaning more likely to be satisfying). \n",
    "\n",
    "My approach is to form a ratio of ratings to calorie count - the higher the score in this metric, the better it is. \n",
    "\n",
    "One thing to watch out for is that ratings and calorie count are on a very different scale. My approach for this is to get the percentile rank for each metric first, and then compute for the ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13594.000000\n",
       "mean         3.907401\n",
       "std         43.968667\n",
       "min          0.042046\n",
       "25%          0.514264\n",
       "50%          0.966821\n",
       "75%          1.852456\n",
       "max       3186.125000\n",
       "Name: rating_calorie_ratio, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_calorie = df[(df['rating'] != 0) & (df['calories'] != 0) & (pd.notnull(df['rating'])) & (pd.notnull(df['calories']))]\n",
    "df_rating_calorie = tukey_rule(df, 'calories')\n",
    "\n",
    "# Compute for percentile ranks\n",
    "df_rating_calorie['pct_rating'] = df_rating_calorie['rating'].rank(pct=True)\n",
    "df_rating_calorie['pct_calories'] = df_rating_calorie['calories'].rank(pct=True)\n",
    "\n",
    "# Compute for rating-calorie ratio\n",
    "df_rating_calorie['rating_calorie_ratio'] = df_rating_calorie['pct_rating'] / df_rating_calorie['pct_calories']\n",
    "df_rating_calorie['rating_calorie_ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top 10 recommended recipes based on rating-to-calorie ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating_calorie_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>To Clarify Butter</td>\n",
       "      <td>3186.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>Dashi (Japanese Sea Stock)</td>\n",
       "      <td>3186.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Salted Water for Boiling</td>\n",
       "      <td>1122.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>Wakame</td>\n",
       "      <td>849.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17662</th>\n",
       "      <td>Dashi</td>\n",
       "      <td>606.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Za'atar</td>\n",
       "      <td>480.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>Brain-Boosting Broth</td>\n",
       "      <td>480.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13967</th>\n",
       "      <td>The Manhattan</td>\n",
       "      <td>472.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7321</th>\n",
       "      <td>Garlic Broth</td>\n",
       "      <td>472.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15115</th>\n",
       "      <td>Fresh Vegetable Platter with Olive Oil Dip</td>\n",
       "      <td>472.473684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  rating_calorie_ratio\n",
       "4848                            To Clarify Butter            3186.125000\n",
       "6089                   Dashi (Japanese Sea Stock)            3186.125000\n",
       "285                      Salted Water for Boiling            1122.125000\n",
       "5324                                       Wakame             849.633333\n",
       "17662                                       Dashi             606.166667\n",
       "615                                       Za'atar             480.924528\n",
       "14443                        Brain-Boosting Broth             480.924528\n",
       "13967                               The Manhattan             472.473684\n",
       "7321                                 Garlic Broth             472.473684\n",
       "15115  Fresh Vegetable Platter with Olive Oil Dip             472.473684"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_calorie.sort_values(by =['rating_calorie_ratio'], ascending=False)[['title','rating_calorie_ratio']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) What other questions can we seek to answer given this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following can be done for further analysis:\n",
    "    \n",
    "1) What is the most optimal combination of ingredient that would lead to highest rating? (Can be answered through market basket analysis) <br>\n",
    "2) What are the key recipe categories / clusters? (Can be answered through cluster analysis) <br>\n",
    "3) Which ingredients influence the ratings / caloric content the most? (Can be answered through modeling techniques such as regression / classification / machine learning)\n",
    "\n",
    "Furthermore, we can do a more effective cleaning of the data through modeling, or researching for better ingredient libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
